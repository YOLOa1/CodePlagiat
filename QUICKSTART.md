# ğŸš€ Guide de DÃ©marrage Rapide

## ğŸ“‹ PrÃ©requis

- Docker Desktop installÃ© et dÃ©marrÃ©
- Au moins 8 GB de RAM disponible
- Ports disponibles: 8080, 8081, 8082, 8501, 9000, 9870

## âš¡ DÃ©marrage en 5 Minutes

### 1ï¸âƒ£ Cloner et naviguer vers le projet
```powershell
cd d:\CodePlagiat
```

### 2ï¸âƒ£ Build des images Docker
```powershell
docker-compose build
```
â±ï¸ DurÃ©e estimÃ©e: 10-15 minutes (premiÃ¨re fois uniquement)

### 3ï¸âƒ£ DÃ©marrer le cluster
```powershell
docker-compose up -d
```
â±ï¸ DurÃ©e: 30-60 secondes

### 4ï¸âƒ£ VÃ©rifier l'Ã©tat des conteneurs
```powershell
docker-compose ps
```

Vous devriez voir 4 conteneurs:
- âœ… `spark-master` (healthy)
- âœ… `spark-worker-1` (healthy)
- âœ… `spark-worker-2` (healthy)
- âœ… `app-client` (healthy)

### 5ï¸âƒ£ AccÃ©der aux interfaces

| Service | URL | Description |
|---------|-----|-------------|
| ğŸŒ **Application Streamlit** | http://localhost:8501 | Interface utilisateur |
| âš¡ **Spark Master UI** | http://localhost:8080 | Monitoring Spark |
| ğŸ‘· **Worker 1 UI** | http://localhost:8081 | Ã‰tat Worker 1 |
| ğŸ‘· **Worker 2 UI** | http://localhost:8082 | Ã‰tat Worker 2 |
| ğŸ“ **HDFS NameNode UI** | http://localhost:9870 | SystÃ¨me de fichiers |

## ğŸ§ª Test Rapide

### Option 1: Via l'interface Streamlit

1. Ouvrir http://localhost:8501
2. Uploader des fichiers sources (`.py`, `.cpp`, `.java`)
3. Cliquer sur "Upload vers HDFS"
4. Cliquer sur "DÃ©marrer l'analyse"
5. Consulter les rÃ©sultats dans l'onglet "RÃ©sultats"

### Option 2: Via la ligne de commande

```powershell
# 1. Copier les exemples vers HDFS
docker exec spark-master hdfs dfs -put /app/data/input/*.py /app/input/

# 2. Lancer le job PySpark
docker exec spark-master spark-submit `
  --master spark://spark-master:7077 `
  /app/src/spark_jobs/detect_plagiarism.py `
  --input hdfs://spark-master:9000/app/input `
  --output hdfs://spark-master:9000/app/output

# 3. Voir les rÃ©sultats
docker exec spark-master hdfs dfs -cat /app/output/part-00000-*.csv
```

## ğŸ“Š Commandes Utiles

### Gestion du Cluster

```powershell
# ArrÃªter le cluster
docker-compose down

# ArrÃªter et supprimer les volumes (rÃ©initialisation complÃ¨te)
docker-compose down -v

# Voir les logs d'un conteneur
docker-compose logs -f spark-master

# RedÃ©marrer un service
docker-compose restart spark-worker-1
```

### Interaction avec HDFS

```powershell
# Lister les fichiers HDFS
docker exec spark-master hdfs dfs -ls /app/input

# CrÃ©er un rÃ©pertoire
docker exec spark-master hdfs dfs -mkdir -p /app/test

# Upload un fichier
docker exec spark-master hdfs dfs -put /app/data/input/example1.py /app/input/

# TÃ©lÃ©charger un fichier
docker exec spark-master hdfs dfs -get /app/output/results.csv /tmp/

# Supprimer un fichier
docker exec spark-master hdfs dfs -rm /app/input/example1.py
```

### Interaction avec Spark

```powershell
# Lancer un shell PySpark
docker exec -it spark-master pyspark --master spark://spark-master:7077

# Voir les applications Spark actives
docker exec spark-master curl http://localhost:8080/json/

# Tuer une application Spark
docker exec spark-master /opt/spark/sbin/stop-all.sh
docker exec spark-master /opt/spark/sbin/start-all.sh
```

## ğŸ” DÃ©pannage

### ProblÃ¨me: Les conteneurs ne dÃ©marrent pas

**Solution:**
```powershell
# VÃ©rifier les logs
docker-compose logs

# RÃ©initialiser complÃ¨tement
docker-compose down -v
docker-compose build --no-cache
docker-compose up -d
```

### ProblÃ¨me: HDFS NameNode ne dÃ©marre pas

**Solution:**
```powershell
# Reformater le NameNode
docker exec spark-master hdfs namenode -format -force
docker-compose restart spark-master
```

### ProblÃ¨me: Spark Workers ne se connectent pas

**Solution:**
```powershell
# VÃ©rifier que le Master est dÃ©marrÃ©
docker exec spark-master nc -zv spark-master 7077

# RedÃ©marrer les workers
docker-compose restart spark-worker-1 spark-worker-2
```

### ProblÃ¨me: Port dÃ©jÃ  utilisÃ©

**Solution:**
```powershell
# Trouver le processus utilisant le port
netstat -ano | findstr :8080

# Tuer le processus (remplacer PID)
taskkill /PID <PID> /F

# Ou modifier les ports dans docker-compose.yml
```

## ğŸ“ˆ Monitoring

### VÃ©rifier la santÃ© du cluster

```powershell
# Status des conteneurs
docker-compose ps

# Ressources utilisÃ©es
docker stats

# Logs en temps rÃ©el
docker-compose logs -f --tail=50
```

### MÃ©triques Spark

- **Master UI**: http://localhost:8080
  - Nombre de workers actifs
  - Applications en cours
  - Ressources disponibles

- **Worker UI**: http://localhost:8081 ou 8082
  - Executors actifs
  - MÃ©moire utilisÃ©e
  - TÃ¢ches en cours

### MÃ©triques HDFS

- **NameNode UI**: http://localhost:9870
  - Espace disque utilisÃ©
  - Nombre de DataNodes actifs
  - Nombre de fichiers

## ğŸ“ Prochaines Ã‰tapes

1. **Tester avec vos propres fichiers**
   - Uploader vos codes sources
   - Ajuster les paramÃ¨tres (k, window) dans `winnowing.py`
   - Modifier le seuil de dÃ©tection dans `similarity.py`

2. **Optimiser les performances**
   - Augmenter la mÃ©moire des workers dans `docker-compose.yml`
   - Ajuster le parallÃ©lisme dans `spark-defaults.conf`
   - Activer Kryo serialization pour de meilleures performances

3. **Ajouter des fonctionnalitÃ©s**
   - Support de nouveaux langages (Ruby, Go, etc.)
   - Rapports HTML dÃ©taillÃ©s
   - API REST pour intÃ©gration externe
   - DÃ©tection de patterns spÃ©cifiques

## ğŸ’¡ Astuces

- ğŸ’¾ Les donnÃ©es HDFS sont persistÃ©es dans des volumes Docker
- ğŸ”„ Les logs Spark sont dans `/tmp/spark-events`
- ğŸ“Š Utilisez Spark UI pour dÃ©bugger les jobs lents
- ğŸ› Activez le niveau DEBUG dans `spark-defaults.conf` si nÃ©cessaire

## ğŸ“š Documentation ComplÃ¨te

Consultez le [README.md](README.md) pour plus de dÃ©tails sur:
- Architecture dÃ©taillÃ©e
- Algorithmes utilisÃ©s
- Configuration avancÃ©e
- API et extensibilitÃ©
