# ğŸš€ Guide d'utilisation sans interface Streamlit

Ce guide explique comment utiliser le systÃ¨me de dÃ©tection de plagiat directement en ligne de commande, sans passer par l'interface web.

## ğŸ“‹ Table des matiÃ¨res

- [DÃ©marrage du cluster](#dÃ©marrage-du-cluster)
- [Gestion des fichiers HDFS](#gestion-des-fichiers-hdfs)
- [Lancement d'une analyse](#lancement-dune-analyse)
- [Consultation des rÃ©sultats](#consultation-des-rÃ©sultats)
- [Exemples d'utilisation](#exemples-dutilisation)
- [Commandes avancÃ©es](#commandes-avancÃ©es)

---

## ğŸ¯ DÃ©marrage du cluster

### DÃ©marrer tous les services
```powershell
# DÃ©marrer le cluster complet (Master + 2 Workers + Client)
docker-compose up -d

# VÃ©rifier que tous les conteneurs sont "healthy"
docker ps

# Attendre ~60 secondes pour que tous les services soient prÃªts
```

### ArrÃªter le cluster
```powershell
# ArrÃªter tous les conteneurs
docker-compose down

# ArrÃªter ET supprimer les volumes (âš ï¸ perte de donnÃ©es HDFS)
docker-compose down -v
```

### RedÃ©marrer un service spÃ©cifique
```powershell
# RedÃ©marrer uniquement le Master
docker restart spark-master

# RedÃ©marrer un Worker
docker restart spark-worker-1
```

---

## ğŸ“ Gestion des fichiers HDFS

### Structure des rÃ©pertoires HDFS
```
hdfs://spark-master:9000/
â””â”€â”€ app/
    â”œâ”€â”€ input/          # Fichiers source Ã  analyser
    â”œâ”€â”€ results/        # RÃ©sultats des analyses
    â””â”€â”€ logs/           # Logs optionnels
```

### CrÃ©er la structure de rÃ©pertoires
```powershell
# CrÃ©er les dossiers nÃ©cessaires
docker exec spark-master hdfs dfs -mkdir -p /app/input
docker exec spark-master hdfs dfs -mkdir -p /app/results
docker exec spark-master hdfs dfs -mkdir -p /app/logs
```

### Uploader des fichiers

#### Upload d'un seul fichier
```powershell
# Depuis le conteneur (fichiers dÃ©jÃ  dans /app/data/input/)
docker exec spark-master hdfs dfs -put /app/data/input/mon_fichier.py /app/input/

# Avec un fichier de votre machine Windows
docker cp D:\MesFichiers\code.py spark-master:/tmp/code.py
docker exec spark-master hdfs dfs -put /tmp/code.py /app/input/
```

#### Upload de plusieurs fichiers
```powershell
# Uploader tous les fichiers .py d'un dossier
docker exec spark-master sh -c "cd /app/data/input && for f in *.py; do hdfs dfs -put \$f /app/input/ 2>/dev/null || true; done"

# Avec un dossier de votre machine
docker cp D:\MesFichiers\*.py spark-master:/tmp/
docker exec spark-master sh -c "cd /tmp && for f in *.py; do hdfs dfs -put \$f /app/input/; done"
```

### Lister les fichiers
```powershell
# Lister le contenu de /app/input/
docker exec spark-master hdfs dfs -ls /app/input/

# Liste rÃ©cursive avec tailles
docker exec spark-master hdfs dfs -ls -R -h /app/

# Compter les fichiers
docker exec spark-master hdfs dfs -count /app/input/
```

### Consulter le contenu d'un fichier
```powershell
# Afficher tout le contenu
docker exec spark-master hdfs dfs -cat /app/input/mon_fichier.py

# Afficher les 10 premiÃ¨res lignes
docker exec spark-master hdfs dfs -cat /app/input/mon_fichier.py | head -10

# Afficher les 10 derniÃ¨res lignes
docker exec spark-master hdfs dfs -cat /app/input/mon_fichier.py | tail -10
```

### TÃ©lÃ©charger des fichiers depuis HDFS
```powershell
# TÃ©lÃ©charger vers le conteneur
docker exec spark-master hdfs dfs -get /app/input/mon_fichier.py /tmp/

# Puis copier vers Windows
docker cp spark-master:/tmp/mon_fichier.py D:\MesFichiers\
```

### Supprimer des fichiers
```powershell
# Supprimer un fichier
docker exec spark-master hdfs dfs -rm /app/input/vieux_fichier.py

# Supprimer tous les fichiers d'un dossier
docker exec spark-master hdfs dfs -rm /app/input/*

# Supprimer un dossier et son contenu
docker exec spark-master hdfs dfs -rm -r /app/old_results/

# Vider complÃ¨tement le dossier input
docker exec spark-master hdfs dfs -rm -r /app/input/*
```

### Renommer ou dÃ©placer
```powershell
# Renommer un fichier
docker exec spark-master hdfs dfs -mv /app/input/ancien_nom.py /app/input/nouveau_nom.py

# DÃ©placer vers un autre dossier
docker exec spark-master hdfs dfs -mv /app/input/fichier.py /app/archive/
```

---

## ğŸ” Lancement d'une analyse

### Commande de base (tous contre tous)
```powershell
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/run_$(Get-Date -Format "yyyyMMdd_HHmmss")
```

### Comparaison ciblÃ©e (un fichier vs tous les autres)
```powershell
# Comparer un fichier spÃ©cifique contre toute la base de donnÃ©es
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/target_$(Get-Date -Format "yyyyMMdd_HHmmss") \
  --target student1.py

# Avec le chemin HDFS complet
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/suspect_check \
  --target hdfs://spark-master:9000/app/input/plagiat1.py
```

### Avec configuration personnalisÃ©e
```powershell
# Analyse avec plus de mÃ©moire et de cÅ“urs
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --driver-memory 2g \
  --executor-memory 2g \
  --executor-cores 2 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/analyse_$(Get-Date -Format "yyyyMMdd_HHmmss")
```

### Sauvegarder les logs
```powershell
# Rediriger la sortie vers un fichier
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/run_latest \
  > analyse_log.txt 2>&1
```

---

## ğŸ“Š Consultation des rÃ©sultats

### Lister les dossiers de rÃ©sultats
```powershell
# Voir tous les runs
docker exec spark-master hdfs dfs -ls /app/results/

# DÃ©tails avec dates
docker exec spark-master hdfs dfs -ls -h /app/results/
```

### Afficher les rÃ©sultats

#### RÃ©sultats du dernier run
```powershell
# Afficher le CSV complet
docker exec spark-master hdfs dfs -cat /app/results/run_latest/*.csv

# Afficher uniquement les en-tÃªtes et les 5 premiÃ¨res lignes
docker exec spark-master hdfs dfs -cat /app/results/run_latest/*.csv | head -6
```

#### Filtrer les rÃ©sultats
```powershell
# Uniquement les similaritÃ©s > 70% (plagiat)
docker exec spark-master hdfs dfs -cat /app/results/run_latest/*.csv | awk -F',' '$3 > 0.7 {print}'

# Trier par score de similaritÃ© dÃ©croissant
docker exec spark-master hdfs dfs -cat /app/results/run_latest/*.csv | tail -n +2 | sort -t',' -k3 -rn

# Compter le nombre de plagiats dÃ©tectÃ©s (> 70%)
docker exec spark-master hdfs dfs -cat /app/results/run_latest/*.csv | awk -F',' '$3 > 0.7' | wc -l
```

### TÃ©lÃ©charger les rÃ©sultats
```powershell
# TÃ©lÃ©charger le CSV vers Windows
docker exec spark-master hdfs dfs -cat /app/results/run_latest/*.csv > resultats.csv

# Ouvrir avec Excel
Start-Process resultats.csv
```

### Analyser avec Python
```powershell
# CrÃ©er un script Python pour analyser
docker exec spark-master python3 -c "
import pandas as pd
import subprocess

# Lire depuis HDFS
result = subprocess.run(['hdfs', 'dfs', '-cat', '/app/results/run_latest/*.csv'], 
                       capture_output=True, text=True)
                       
# Charger dans pandas
from io import StringIO
df = pd.read_csv(StringIO(result.stdout))

# Statistiques
print('Nombre total de comparaisons:', len(df))
print('Plagiats dÃ©tectÃ©s (>70%):', len(df[df['similarity_score'] > 0.7]))
print('SimilaritÃ© moyenne:', df['similarity_score'].mean())
print('\nTop 5 des similaritÃ©s:')
print(df.nlargest(5, 'similarity_score'))
"
```

---

## ğŸ¯ Exemples d'utilisation

### Exemple 1: Analyser un devoir d'Ã©tudiants

```powershell
# 1. Nettoyer l'ancien contenu
docker exec spark-master hdfs dfs -rm -r /app/input/*

# 2. Uploader les devoirs (depuis votre dossier local)
$devoirs = Get-ChildItem "D:\Devoirs\TP1\*.py"
foreach ($devoir in $devoirs) {
    docker cp $devoir.FullName "spark-master:/tmp/$($devoir.Name)"
    docker exec spark-master hdfs dfs -put "/tmp/$($devoir.Name)" /app/input/
}

# 3. VÃ©rifier l'upload
docker exec spark-master hdfs dfs -ls /app/input/

# 4. Lancer l'analyse (tous contre tous)
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/tp1_$(Get-Date -Format "yyyyMMdd")

# 5. Voir les plagiats dÃ©tectÃ©s
Write-Host "`n=== PLAGIATS DÃ‰TECTÃ‰S ===" -ForegroundColor Red
docker exec spark-master hdfs dfs -cat /app/results/tp1_*/part-*.csv | Select-String -Pattern "0\.[7-9]|1\.0"
```

### Exemple 1bis: VÃ©rifier un devoir suspect

```powershell
# ScÃ©nario: Un Ã©tudiant a rendu un devoir suspect, vÃ©rifier s'il a copiÃ©
$fichierSuspect = "etudiant_suspect.py"

# 1. S'assurer que tous les devoirs sont dans HDFS (incluant le suspect)
docker exec spark-master hdfs dfs -ls /app/input/

# 2. Comparer UNIQUEMENT ce fichier contre tous les autres
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/verification_suspect \
  --target $fichierSuspect

# 3. Voir immÃ©diatement les rÃ©sultats
Write-Host "`n=== VÃ‰RIFICATION: $fichierSuspect ===" -ForegroundColor Yellow
docker exec spark-master hdfs dfs -cat /app/results/verification_suspect/part-*.csv

# 4. Filtrer uniquement les scores Ã©levÃ©s
Write-Host "`n=== PLAGIATS POTENTIELS (>80%) ===" -ForegroundColor Red
docker exec spark-master hdfs dfs -cat /app/results/verification_suspect/part-*.csv | Select-String -Pattern "0\.[8-9]|1\.0"
```

### Exemple 2: Analyse comparative entre deux versions

```powershell
# Comparer version 2024 vs version 2025 d'un projet
docker exec spark-master hdfs dfs -rm -r /app/input/*

# Upload version 2024
docker exec spark-master sh -c "cd /app/data/input && for f in version2024_*.py; do hdfs dfs -put \$f /app/input/; done"

# Upload version 2025
docker exec spark-master sh -c "cd /app/data/input && for f in version2025_*.py; do hdfs dfs -put \$f /app/input/; done"

# Analyse
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/comparison_2024_vs_2025

# Filtrer uniquement les comparaisons entre versions diffÃ©rentes
docker exec spark-master hdfs dfs -cat /app/results/comparison_*/part-*.csv | Select-String "version2024.*version2025|version2025.*version2024"
```

### Exemple 3: Batch processing de plusieurs projets

```powershell
# Liste de projets Ã  analyser
$projets = @("ProjetA", "ProjetB", "ProjetC")

foreach ($projet in $projets) {
    Write-Host "`n=== Analyse de $projet ===" -ForegroundColor Cyan
    
    # Nettoyer
    docker exec spark-master hdfs dfs -rm -r /app/input/*
    
    # Upload
    docker exec spark-master sh -c "cd /app/data/input/$projet && for f in *.py; do hdfs dfs -put \$f /app/input/; done"
    
    # Analyse
    docker exec spark-master spark-submit \
      --master spark://spark-master:7077 \
      --py-files /app/src/spark_jobs.zip \
      /app/src/spark_jobs/detect_plagiarism.py \
      --input hdfs://spark-master:9000/app/input \
      --output hdfs://spark-master:9000/app/results/${projet}_$(Get-Date -Format "yyyyMMdd")
    
    # RÃ©sumÃ©
    $plagiats = docker exec spark-master hdfs dfs -cat "/app/results/${projet}_*/part-*.csv" | Select-String "0\.[7-9]|1\.0" | Measure-Object -Line
    Write-Host "Plagiats dÃ©tectÃ©s: $($plagiats.Lines)" -ForegroundColor $(if ($plagiats.Lines -gt 0) { "Red" } else { "Green" })
}
```

### Exemple 4: VÃ©rification d'un nouveau fichier contre une base existante

```powershell
# ScÃ©nario: Un nouveau devoir arrive, vÃ©rifier s'il est copiÃ© des anciens
# La base de donnÃ©es contient dÃ©jÃ  100 devoirs des annÃ©es prÃ©cÃ©dentes

# 1. Uploader UNIQUEMENT le nouveau fichier (sans effacer l'ancien contenu)
$nouveauDevoir = "D:\Nouveaux\etudiant_nouveau.py"
docker cp $nouveauDevoir "spark-master:/tmp/nouveau.py"
docker exec spark-master hdfs dfs -put /tmp/nouveau.py /app/input/

# 2. VÃ©rifier combien de fichiers au total
docker exec spark-master hdfs dfs -count /app/input/

# 3. Comparer SEULEMENT ce nouveau fichier contre les 100 anciens
Write-Host "`nğŸ” VÃ©rification du nouveau devoir contre la base..." -ForegroundColor Yellow
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/nouveau_check_$(Get-Date -Format "yyyyMMdd_HHmmss") \
  --target nouveau.py

# 4. Rapport dÃ©taillÃ©
Write-Host "`nğŸ“Š RAPPORT DE VÃ‰RIFICATION:" -ForegroundColor Cyan
$resultats = docker exec spark-master hdfs dfs -cat /app/results/nouveau_check_*/part-*.csv
$totalComparaisons = ($resultats | Measure-Object -Line).Lines - 1  # -1 pour l'en-tÃªte
$plagiats = $resultats | Select-String -Pattern "0\.[7-9]|1\.0" | Measure-Object -Line

Write-Host "  â€¢ Fichier analysÃ©: nouveau.py" -ForegroundColor White
Write-Host "  â€¢ Comparaisons effectuÃ©es: $totalComparaisons" -ForegroundColor White
Write-Host "  â€¢ Plagiats dÃ©tectÃ©s (>70%): $($plagiats.Lines)" -ForegroundColor $(if ($plagiats.Lines -gt 0) { "Red" } else { "Green" })

if ($plagiats.Lines -gt 0) {
    Write-Host "`nâš ï¸ ATTENTION: Plagiats dÃ©tectÃ©s!" -ForegroundColor Red
    $resultats | Select-String -Pattern "0\.[7-9]|1\.0"
} else {
    Write-Host "`nâœ… Aucun plagiat dÃ©tectÃ© - Devoir original" -ForegroundColor Green
}
```

### Exemple 5: Comparaison rapide d'un fichier reÃ§u par email

```powershell
# Workflow rapide pour vÃ©rifier un fichier suspect reÃ§u par email

# 1. DÃ©finir le fichier Ã  vÃ©rifier
$fichierEmail = "D:\Downloads\code_suspect_from_email.py"
$nomFichier = Split-Path $fichierEmail -Leaf

# 2. Upload rapide (la base existe dÃ©jÃ  dans HDFS)
Write-Host "ğŸ“¤ Upload du fichier suspect..." -ForegroundColor Yellow
docker cp $fichierEmail "spark-master:/tmp/suspect.py"
docker exec spark-master hdfs dfs -put -f /tmp/suspect.py /app/input/suspect.py

# 3. Lancer l'analyse ciblÃ©e (plus rapide que tous contre tous)
Write-Host "ğŸ” Analyse en cours..." -ForegroundColor Yellow
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --driver-memory 1g \
  --executor-memory 1g \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/email_check \
  --target suspect.py

# 4. RÃ©sultat immÃ©diat
Write-Host "`nğŸ“‹ RÃ‰SULTATS:" -ForegroundColor Cyan
docker exec spark-master hdfs dfs -cat /app/results/email_check/part-*.csv | 
    ConvertFrom-Csv | 
    Where-Object { [float]$_.similarity_score -gt 0.7 } |
    Sort-Object { [float]$_.similarity_score } -Descending |
    Format-Table -AutoSize

# 5. Nettoyer le fichier temporaire
docker exec spark-master hdfs dfs -rm /app/input/suspect.py
Write-Host "`nâœ… VÃ©rification terminÃ©e" -ForegroundColor Green
```

---

## ğŸ› ï¸ Commandes avancÃ©es

### Monitoring du cluster

```powershell
# Voir les applications Spark en cours
docker exec spark-master curl -s http://localhost:8080/json/ | ConvertFrom-Json | Select-Object -ExpandProperty activeapps

# Statistiques HDFS
docker exec spark-master hdfs dfsadmin -report

# SantÃ© des DataNodes
docker exec spark-master hdfs dfsadmin -printTopology

# Logs du Master
docker logs spark-master --tail 50

# Logs d'un Worker
docker logs spark-worker-1 --tail 50
```

### Gestion de la mÃ©moire

```powershell
# Voir l'utilisation mÃ©moire des conteneurs
docker stats --no-stream

# Nettoyer le cache Spark
docker exec spark-master rm -rf /tmp/spark-*

# Nettoyer les anciens rÃ©sultats (garde les 5 derniers)
docker exec spark-master hdfs dfs -ls /app/results/ | tail -n +6 | awk '{print $8}' | xargs -I {} hdfs dfs -rm -r {}
```

### Debugging

```powershell
# ExÃ©cuter un job avec plus de logs
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --conf spark.executor.extraJavaOptions="-Dlog4j.configuration=file:///opt/spark/conf/log4j.properties" \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/debug_run

# Tester la connexion HDFS
docker exec spark-master hdfs dfs -test -e /app/input && echo "Dossier existe" || echo "Dossier n'existe pas"

# VÃ©rifier la santÃ© de Spark
docker exec spark-master curl -s http://localhost:8080/json/ | python3 -m json.tool

# Shell interactif Python avec PySpark
docker exec -it spark-master pyspark --master spark://spark-master:7077
```

### Export et sauvegarde

```powershell
# Exporter tous les rÃ©sultats vers un dossier local
$date = Get-Date -Format "yyyyMMdd_HHmmss"
New-Item -ItemType Directory -Path ".\exports\export_$date" -Force
docker exec spark-master hdfs dfs -get /app/results/* /tmp/export/
docker cp spark-master:/tmp/export/. ".\exports\export_$date\"

# CrÃ©er un backup HDFS
docker exec spark-master hdfs dfs -cp /app /app_backup_$(Get-Date -Format "yyyyMMdd")

# Archiver et compresser
docker exec spark-master tar -czf /tmp/hdfs_backup.tar.gz /hdfs/
docker cp spark-master:/tmp/hdfs_backup.tar.gz .\backups\
```

---

## ğŸ“š Ressources supplÃ©mentaires

### Interfaces Web disponibles

- **Spark Master UI**: http://localhost:8080 - Ã‰tat du cluster, applications, workers
- **Spark Worker 1 UI**: http://localhost:8081 - MÃ©triques du worker 1
- **Spark Worker 2 UI**: http://localhost:8082 - MÃ©triques du worker 2
- **HDFS NameNode UI**: http://localhost:9870 - Parcourir HDFS, Ã©tat des DataNodes

### Scripts PowerShell utiles

#### Script de monitoring continu
```powershell
# monitor.ps1
while ($true) {
    Clear-Host
    Write-Host "=== Ã‰TAT DU CLUSTER ===" -ForegroundColor Green
    docker ps --filter "name=spark" --format "table {{.Names}}\t{{.Status}}"
    
    Write-Host "`n=== FICHIERS HDFS ===" -ForegroundColor Cyan
    docker exec spark-master hdfs dfs -count /app/input /app/results
    
    Write-Host "`n=== APPLICATIONS SPARK ===" -ForegroundColor Yellow
    docker exec spark-master curl -s http://localhost:8080/json/ | ConvertFrom-Json | Select-Object -ExpandProperty activeapps | Format-Table
    
    Start-Sleep 5
}
```

#### Script d'analyse automatique
```powershell
# auto_analyze.ps1
param(
    [string]$InputFolder,
    [string]$OutputName = "batch_$(Get-Date -Format 'yyyyMMdd_HHmmss')"
)

Write-Host "ğŸš€ DÃ©marrage de l'analyse automatique..." -ForegroundColor Green

# 1. Nettoyer HDFS
Write-Host "ğŸ“ Nettoyage HDFS..." -ForegroundColor Yellow
docker exec spark-master hdfs dfs -rm -r /app/input/* 2>$null

# 2. Upload des fichiers
Write-Host "ğŸ“¤ Upload des fichiers..." -ForegroundColor Yellow
$files = Get-ChildItem "$InputFolder\*.py"
foreach ($file in $files) {
    docker cp $file.FullName "spark-master:/tmp/$($file.Name)"
    docker exec spark-master hdfs dfs -put "/tmp/$($file.Name)" /app/input/
}

Write-Host "âœ… $($files.Count) fichiers uploadÃ©s" -ForegroundColor Green

# 3. Lancement de l'analyse
Write-Host "ğŸ” Lancement de l'analyse..." -ForegroundColor Yellow
docker exec spark-master spark-submit `
  --master spark://spark-master:7077 `
  --py-files /app/src/spark_jobs.zip `
  /app/src/spark_jobs/detect_plagiarism.py `
  --input hdfs://spark-master:9000/app/input `
  --output hdfs://spark-master:9000/app/results/$OutputName

# 4. Affichage des rÃ©sultats
Write-Host "`nğŸ“Š RÃ‰SULTATS:" -ForegroundColor Cyan
docker exec spark-master hdfs dfs -cat "/app/results/$OutputName/part-*.csv"

Write-Host "`nâœ… Analyse terminÃ©e! RÃ©sultats dans: /app/results/$OutputName" -ForegroundColor Green
```

---

## ğŸ†˜ DÃ©pannage

### Le cluster ne dÃ©marre pas
```powershell
# VÃ©rifier les logs
docker-compose logs

# Reconstruire les images
docker-compose build --no-cache

# Reset complet
docker-compose down -v
docker-compose up -d
```

### Erreur "No space left on device"
```powershell
# Nettoyer les anciens rÃ©sultats
docker exec spark-master hdfs dfs -rm -r /app/results/run_* | Select-Object -First 10

# Nettoyer Docker
docker system prune -a --volumes
```

### Job Spark Ã©choue
```powershell
# VÃ©rifier que l'archive des modules existe
docker exec spark-master ls -lh /app/src/spark_jobs.zip

# RecrÃ©er l'archive si nÃ©cessaire
docker exec spark-master python3 -c "import shutil; shutil.make_archive('/app/src/spark_jobs', 'zip', '/app/src', 'spark_jobs')"

# Tester avec moins de mÃ©moire
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --driver-memory 512m \
  --executor-memory 512m \
  --py-files /app/src/spark_jobs.zip \
  /app/src/spark_jobs/detect_plagiarism.py \
  --input hdfs://spark-master:9000/app/input \
  --output hdfs://spark-master:9000/app/results/test
```

---

**ğŸ’¡ Astuce**: Pour une utilisation interactive et plus conviviale, utilisez l'interface Streamlit sur http://localhost:8501 !
