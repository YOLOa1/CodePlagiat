# ğŸ“ Structure ComplÃ¨te du Projet

```
CodePlagiat/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                          # Documentation principale
â”œâ”€â”€ ğŸ“„ QUICKSTART.md                      # Guide de dÃ©marrage rapide
â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md                    # Architecture dÃ©taillÃ©e
â”œâ”€â”€ ğŸ“„ LICENSE                            # Licence MIT
â”œâ”€â”€ ğŸ“„ .gitignore                         # Fichiers Ã  ignorer par Git
â”œâ”€â”€ ğŸ“„ Makefile                           # Commandes rapides
â”œâ”€â”€ ğŸ“„ docker-compose.yml                 # Orchestration Docker
â”‚
â”œâ”€â”€ ğŸ³ docker/                            # Fichiers Docker
â”‚   â”œâ”€â”€ Dockerfile.base                   # Image de base (Spark/Hadoop/Python)
â”‚   â”œâ”€â”€ Dockerfile.client                 # Image client (Streamlit)
â”‚   â”œâ”€â”€ entrypoint.sh                     # Script de dÃ©marrage conditionnel
â”‚   â””â”€â”€ requirements.txt                  # DÃ©pendances Python
â”‚
â”œâ”€â”€ âš™ï¸ configs/                           # Configurations
â”‚   â”œâ”€â”€ hdfs-site.xml                     # Configuration HDFS
â”‚   â””â”€â”€ spark-defaults.conf               # Configuration Spark
â”‚
â”œâ”€â”€ ğŸ’» src/                               # Code source
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”¥ spark_jobs/                    # Jobs PySpark
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ detect_plagiarism.py          # Job principal de dÃ©tection
â”‚   â”‚   â”œâ”€â”€ ast_extractor.py              # Extraction AST
â”‚   â”‚   â”œâ”€â”€ winnowing.py                  # Algorithme Winnowing
â”‚   â”‚   â””â”€â”€ similarity.py                 # Calcul de similaritÃ©
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸŒ client/                        # Application Web
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py                        # Interface Streamlit
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ”§ utils/                         # Utilitaires
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ hdfs_utils.py                 # Utilitaires HDFS
â”‚       â””â”€â”€ spark_utils.py                # Utilitaires Spark
â”‚
â””â”€â”€ ğŸ“Š data/                              # DonnÃ©es
    â”œâ”€â”€ input/                            # Fichiers sources Ã  analyser
    â”‚   â”œâ”€â”€ example1.py                   # Exemple Python 1
    â”‚   â”œâ”€â”€ example2.py                   # Exemple Python 2
    â”‚   â””â”€â”€ example3.py                   # Exemple Python 3
    â”œâ”€â”€ output/                           # RÃ©sultats d'analyse
    â”‚   â””â”€â”€ .gitkeep
    â””â”€â”€ logs/                             # Logs systÃ¨me
        â””â”€â”€ .gitkeep
```

## ğŸ“ Description des Fichiers ClÃ©s

### ğŸ³ Docker

**docker-compose.yml**
- DÃ©finit 4 services : Master, Worker1, Worker2, Client
- Configure les rÃ©seaux et volumes persistants
- GÃ¨re les dÃ©pendances et health checks

**docker/Dockerfile.base**
- Image complÃ¨te avec Java 11, Hadoop 3.3.1, Spark 3.3.0
- Python 3.9 + dÃ©pendances (PySpark, tree-sitter)
- Compilateurs C++/Java pour analyse AST
- Taille finale : ~2.5 GB

**docker/entrypoint.sh**
- GÃ¨re le dÃ©marrage conditionnel (Master/Worker/Client)
- Initialise HDFS NameNode sur le Master
- DÃ©marre les services Spark selon le rÃ´le

### âš™ï¸ Configuration

**configs/hdfs-site.xml**
- Configuration HDFS distribuÃ©e
- RÃ©plication : 1 (dev) / 3 (prod)
- Taille de bloc : 128 MB
- Permissions dÃ©sactivÃ©es (dev)

**configs/spark-defaults.conf**
- Ressources : 2GB/executor, 2 cores/executor
- ParallÃ©lisme : 4
- Event logs activÃ©s
- Compression des donnÃ©es

### ğŸ’» Code Source

**src/spark_jobs/detect_plagiarism.py** (300+ lignes)
- Job PySpark principal
- Pipeline complet : lecture â†’ AST â†’ winnowing â†’ comparaison â†’ sauvegarde
- Arguments : --input, --output, --master
- Logging dÃ©taillÃ© et gestion d'erreurs

**src/spark_jobs/ast_extractor.py** (230+ lignes)
- Extraction de tokens depuis code source
- Support : Python (natif), C++, Java (regex)
- Normalisation et nettoyage
- Option d'intÃ©gration avec tree-sitter

**src/spark_jobs/winnowing.py** (250+ lignes)
- Algorithme Winnowing complet
- GÃ©nÃ©ration de k-grams (k=5)
- FenÃªtre glissante (w=4)
- Hashing MD5 pour robustesse

**src/spark_jobs/similarity.py** (270+ lignes)
- MÃ©trique Jaccard (principale)
- Autres mÃ©triques : Cosine, Dice, Containment
- CatÃ©gorisation de similaritÃ©
- Comparaison dÃ©taillÃ©e et batch

**src/client/app.py** (400+ lignes)
- Interface Streamlit complÃ¨te
- Upload de fichiers vers HDFS
- Soumission de jobs Spark
- Visualisation avec Plotly
- Export CSV des rÃ©sultats

**src/utils/hdfs_utils.py** (150+ lignes)
- Client HDFS Python
- OpÃ©rations : upload, download, list, delete
- Upload rÃ©cursif de rÃ©pertoires

**src/utils/spark_utils.py** (100+ lignes)
- CrÃ©ation de SparkSession
- Utilitaires de configuration
- Monitoring et debugging

### ğŸ“Š DonnÃ©es

**data/input/example*.py**
- Exemples de code Python
- example1.py et example2.py : similaires (factorielle)
- example3.py : diffÃ©rent (tri Ã  bulles)
- Permet de tester immÃ©diatement le systÃ¨me

## ğŸ¯ Points d'EntrÃ©e

### 1. Interface Web (RecommandÃ©)
```bash
# AccÃ©der Ã  l'application
http://localhost:8501
```

### 2. Ligne de Commande
```bash
# Soumettre un job directement
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  /app/src/spark_jobs/detect_plagiarism.py
```

### 3. Shell PySpark Interactif
```bash
# Pour tester et dÃ©bugger
docker exec -it spark-master pyspark \
  --master spark://spark-master:7077
```

## ğŸ“¦ Volumes Docker

**Volumes persistants crÃ©Ã©s automatiquement :**
- `spark-master-data` : MÃ©tadonnÃ©es HDFS NameNode
- `spark-worker-1-data` : DonnÃ©es HDFS Worker 1
- `spark-worker-2-data` : DonnÃ©es HDFS Worker 2
- `spark-logs` : Logs Spark partagÃ©s

**Volumes montÃ©s depuis l'hÃ´te :**
- `./src` â†’ `/app/src` : Code source (modifiable Ã  chaud)
- `./data` â†’ `/app/data` : DonnÃ©es locales
- `./configs` â†’ `/app/configs` : Configurations

## ğŸŒ Ports ExposÃ©s

| Port | Service | Description |
|------|---------|-------------|
| 8501 | Streamlit | Interface Web principale |
| 8080 | Spark Master | WebUI Master |
| 8081 | Spark Worker 1 | WebUI Worker 1 |
| 8082 | Spark Worker 2 | WebUI Worker 2 |
| 7077 | Spark Master | Communication RPC |
| 9000 | HDFS NameNode | Communication RPC |
| 9870 | HDFS NameNode | WebUI HDFS |
| 9864 | HDFS DataNode 1 | DataNode 1 |
| 9865 | HDFS DataNode 2 | DataNode 2 |

## ğŸ” Metrics & Monitoring

### Spark Master UI (http://localhost:8080)
- Workers actifs
- Applications en cours
- Ressources allouÃ©es
- Historique des jobs

### HDFS NameNode UI (http://localhost:9870)
- Espace disque utilisÃ©/disponible
- Nombre de DataNodes actifs
- Browsing du systÃ¨me de fichiers
- SantÃ© du cluster

### Streamlit (http://localhost:8501)
- Upload et gestion des fichiers
- Lancement et suivi des analyses
- Visualisation des rÃ©sultats
- Export des rapports

## ğŸš€ Workflow Complet

```mermaid
graph TD
    A[Uploader fichiers via Streamlit] --> B[Stockage dans HDFS]
    B --> C[Lancer job Spark]
    C --> D[Extraction AST parallÃ¨le]
    D --> E[GÃ©nÃ©ration empreintes Winnowing]
    E --> F[Comparaison par paires]
    F --> G[Calcul similaritÃ© Jaccard]
    G --> H[Filtrage et tri]
    H --> I[Sauvegarde rÃ©sultats HDFS]
    I --> J[Visualisation dans Streamlit]
```

## ğŸ“ˆ Taille des Fichiers

| Fichier | Lignes | Taille |
|---------|--------|--------|
| detect_plagiarism.py | ~350 | ~15 KB |
| ast_extractor.py | ~230 | ~9 KB |
| winnowing.py | ~250 | ~10 KB |
| similarity.py | ~270 | ~12 KB |
| app.py | ~400 | ~18 KB |
| Dockerfile.base | ~200 | ~8 KB |
| docker-compose.yml | ~200 | ~7 KB |
| **TOTAL Code** | **~2000** | **~80 KB** |

## ğŸ“ Pour Aller Plus Loin

### AmÃ©liorations Possibles

1. **Algorithmes avancÃ©s**
   - LSH (Locality-Sensitive Hashing) pour scalabilitÃ©
   - Graphes de dÃ©pendances de code
   - DÃ©tection de refactoring

2. **Features supplÃ©mentaires**
   - Support de plus de langages (Go, Rust, TypeScript)
   - DÃ©tection de patterns spÃ©cifiques (design patterns)
   - Analyse de similaritÃ© sÃ©mantique (embeddings)

3. **Infrastructure**
   - DÃ©ploiement Kubernetes
   - Auto-scaling des workers
   - Monitoring avec Prometheus/Grafana

4. **Interface**
   - API REST pour intÃ©gration
   - Dashboard temps rÃ©el
   - Rapports PDF dÃ©taillÃ©s

### Ressources

- ğŸ“š [Documentation Apache Spark](https://spark.apache.org/docs/latest/)
- ğŸ“ [Cours Spark sur Coursera](https://www.coursera.org/learn/scala-spark-big-data)
- ğŸ“– [Winnowing Algorithm Paper](https://theory.stanford.edu/~aiken/publications/papers/sigmod03.pdf)
- ğŸ’¡ [GitHub - Awesome Spark](https://github.com/awesome-spark/awesome-spark)

---

**Version:** 1.0  
**Date:** November 2025  
**Auteur:** CodePlagiat Project  
**Licence:** MIT
