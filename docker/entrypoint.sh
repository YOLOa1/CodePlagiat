#!/bin/bash
# ============================================
# Entrypoint Script - D√©marrage Conditionnel
# ============================================
# Ce script g√®re le d√©marrage des conteneurs selon leur r√¥le :
# - MASTER : Lance Spark Master + HDFS NameNode
# - WORKER : Lance Spark Worker + HDFS DataNode
# - CLIENT : Lance uniquement le client (pas de services Spark/HDFS)
# ============================================

set -e

# R√©cup√©ration du r√¥le depuis la variable d'environnement
ROLE=${SPARK_ROLE:-worker}

echo "================================================"
echo "üöÄ D√©marrage du conteneur en mode: $ROLE"
echo "================================================"

# ============================================
# FONCTION: Initialisation HDFS NameNode
# ============================================
init_hdfs_namenode() {
    echo "üìÅ Initialisation du HDFS NameNode..."
    
    # V√©rifier si le NameNode est d√©j√† format√©
    if [ ! -d "/hdfs/namenode/current" ]; then
        echo "‚öôÔ∏è  Formatage du NameNode (premi√®re ex√©cution)..."
        $HADOOP_HOME/bin/hdfs namenode -format -force -nonInteractive
    else
        echo "‚úÖ NameNode d√©j√† format√©, passage au d√©marrage..."
    fi
    
    # D√©marrage du NameNode
    echo "üîÑ D√©marrage du NameNode..."
    $HADOOP_HOME/bin/hdfs --daemon start namenode
    
    # Attendre que le NameNode soit pr√™t
    echo "‚è≥ Attente du NameNode (cela peut prendre jusqu'√† 60 secondes)..."
    timeout=60
    while [ $timeout -gt 0 ]; do
        if nc -z 0.0.0.0 9000 2>/dev/null || nc -z localhost 9000 2>/dev/null; then
            break
        fi
        sleep 2
        timeout=$((timeout - 2))
    done
    
    if [ $timeout -le 0 ]; then
        echo "‚ö†Ô∏è  Timeout: NameNode prend plus de temps, continuons quand m√™me..."
    fi
    
    echo "‚úÖ NameNode d√©marr√© avec succ√®s"
    
    # Cr√©er les r√©pertoires HDFS n√©cessaires
    echo "üìÇ Cr√©ation de la structure HDFS..."
    $HADOOP_HOME/bin/hdfs dfs -mkdir -p /user
    $HADOOP_HOME/bin/hdfs dfs -mkdir -p /app/input
    $HADOOP_HOME/bin/hdfs dfs -mkdir -p /app/output
    $HADOOP_HOME/bin/hdfs dfs -mkdir -p /app/logs
    $HADOOP_HOME/bin/hdfs dfs -chmod -R 777 /
    
    echo "‚úÖ Structure HDFS cr√©√©e"
}

# ============================================
# FONCTION: D√©marrage HDFS DataNode
# ============================================
start_hdfs_datanode() {
    echo "üìÅ D√©marrage du HDFS DataNode..."
    
    # Attendre que le NameNode soit accessible
    echo "‚è≥ Attente du NameNode (spark-master:9000)..."
    timeout=120
    while [ $timeout -gt 0 ]; do
        if nc -z spark-master 9000 2>/dev/null; then
            break
        fi
        sleep 2
        timeout=$((timeout - 2))
    done
    
    if [ $timeout -le 0 ]; then
        echo "‚ö†Ô∏è  Timeout: Continuons sans attendre le NameNode..."
    fi
    
    echo "‚úÖ NameNode accessible"
    
    # D√©marrage du DataNode
    $HADOOP_HOME/bin/hdfs --daemon start datanode
    
    echo "‚úÖ DataNode d√©marr√© avec succ√®s"
}

# ============================================
# FONCTION: D√©marrage Spark Master
# ============================================
start_spark_master() {
    echo "‚ö° D√©marrage du Spark Master..."
    
    # D√©finir le hostname du master
    export SPARK_MASTER_HOST=${SPARK_MASTER_HOST:-spark-master}
    export SPARK_MASTER_PORT=${SPARK_MASTER_PORT:-7077}
    export SPARK_MASTER_WEBUI_PORT=${SPARK_MASTER_WEBUI_PORT:-8080}
    
    # D√©marrage du Master
    $SPARK_HOME/sbin/start-master.sh
    
    echo "‚úÖ Spark Master d√©marr√© sur spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT"
    echo "üåê WebUI accessible sur http://localhost:$SPARK_MASTER_WEBUI_PORT"
}

# ============================================
# FONCTION: D√©marrage Spark Worker
# ============================================
start_spark_worker() {
    echo "‚ö° D√©marrage du Spark Worker..."
    
    # Attendre que le Master soit accessible
    MASTER_URL="spark://${SPARK_MASTER_HOST:-spark-master}:${SPARK_MASTER_PORT:-7077}"
    echo "‚è≥ Attente du Spark Master ($MASTER_URL)..."
    
    timeout=120
    while [ $timeout -gt 0 ]; do
        if nc -z ${SPARK_MASTER_HOST:-spark-master} ${SPARK_MASTER_PORT:-7077} 2>/dev/null; then
            break
        fi
        sleep 2
        timeout=$((timeout - 2))
    done
    
    if [ $timeout -le 0 ]; then
        echo "‚ö†Ô∏è  Timeout: Continuons sans attendre le Master..."
    fi
    
    echo "‚úÖ Spark Master accessible"
    
    # Configuration du Worker
    export SPARK_WORKER_CORES=${SPARK_WORKER_CORES:-2}
    export SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY:-2g}
    export SPARK_WORKER_PORT=${SPARK_WORKER_PORT:-7078}
    export SPARK_WORKER_WEBUI_PORT=${SPARK_WORKER_WEBUI_PORT:-8081}
    
    # D√©marrage du Worker
    $SPARK_HOME/sbin/start-worker.sh $MASTER_URL
    
    echo "‚úÖ Spark Worker d√©marr√©"
    echo "   - Cores: $SPARK_WORKER_CORES"
    echo "   - Memory: $SPARK_WORKER_MEMORY"
    echo "üåê WebUI accessible sur http://localhost:$SPARK_WORKER_WEBUI_PORT"
}

# ============================================
# BRANCHEMENT SELON LE R√îLE
# ============================================
case "$ROLE" in
    master)
        echo "üéØ Configuration en mode MASTER"
        echo "---"
        
        # Initialisation et d√©marrage HDFS NameNode
        init_hdfs_namenode
        
        # D√©marrage Spark Master
        start_spark_master
        
        echo "---"
        echo "‚úÖ Master compl√®tement initialis√©"
        echo "üìä Services actifs:"
        echo "   - HDFS NameNode (port 9000, UI: 9870)"
        echo "   - Spark Master (port 7077, UI: 8080)"
        echo "================================================"
        ;;
        
    worker)
        echo "üéØ Configuration en mode WORKER"
        echo "---"
        
        # D√©marrage HDFS DataNode
        start_hdfs_datanode
        
        # D√©marrage Spark Worker
        start_spark_worker
        
        echo "---"
        echo "‚úÖ Worker compl√®tement initialis√©"
        echo "üìä Services actifs:"
        echo "   - HDFS DataNode (port 9864)"
        echo "   - Spark Worker (port 7078, UI: 8081)"
        echo "================================================"
        ;;
        
    client)
        echo "üéØ Configuration en mode CLIENT"
        echo "---"
        echo "‚úÖ Mode client - Aucun service Spark/HDFS √† d√©marrer"
        echo "================================================"
        ;;
        
    *)
        echo "‚ùå Erreur: R√¥le invalide '$ROLE'"
        echo "R√¥les valides: master, worker, client"
        exit 1
        ;;
esac

# ============================================
# EX√âCUTION DE LA COMMANDE PASS√âE EN PARAM√àTRE
# ============================================
# Si une commande est pass√©e au conteneur, l'ex√©cuter
# Sinon, garder le conteneur actif
if [ $# -gt 0 ]; then
    echo "üîß Ex√©cution de la commande: $@"
    exec "$@"
else
    echo "‚ôæÔ∏è  Conteneur en mode daemon - Maintien actif..."
    # Garder le conteneur actif ind√©finiment
    tail -f /dev/null
fi
